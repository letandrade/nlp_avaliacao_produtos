<h1 align="center"> An√°lise de Sentimentos em Avalia√ß√µes de Produtos Amazon<br /> </h1>

## **1.0 Vis√£o geral**

Este projeto tem como objetivo principal analisar e classificar avalia√ß√µes de produtos da Amazon, identificando automaticamente se uma avalia√ß√£o √© positiva ou negativa. A partir de uma base real de avalia√ß√µes, implementei 3 diferentes abordagens de processamento de linguagem natural (NLP) para transformar textos em dados estruturados e aplicar algoritmos de classifica√ß√£o para prever o sentimento das avalia√ß√µes.

A base de dados utilizada neste projeto foi obtida por meio de web scraping realizado na Amazon e disponibilizada por um usu√°rio da comunidade no Kaggle, atrav√©s do seguinte link:

üîó [Amazon Product Review Dataset on Kaggle](https://www.kaggle.com/datasets/sampaiovitor/avaliaes-em-portugus-amazon-e-mercado-livre)/)

> ‚ö†Ô∏è **Observa√ß√£o:** O autor do dataset n√£o especifica o per√≠odo de coleta das avalia√ß√µes nem fornece detalhes adicionais sobre a metodologia de extra√ß√£o. Por se tratar de dados obtidos via scraping, √© importante considerar poss√≠veis limita√ß√µes quanto √† representatividade temporal e √† completude das informa√ß√µes.

O projeto tem impacto direto em √°reas como com√©rcio eletr√¥nico, suporte ao cliente e an√°lise de reputa√ß√£o de produtos, permitindo automatizar a triagem de feedbacks dos consumidores, identificar produtos mal avaliados com maior rapidez e fornecer insights relevantes para decis√µes de marketing e melhorias de produto.

## **2.0 Objetivos t√©cnicos**

Al√©m da constru√ß√£o dos classificadores, o objetivo t√©cnico deste projeto √© a entrega de planilhas em formato Excel contendo os resultados da an√°lise de sentimentos. Para cada uma das tr√™s abordagens de classifica√ß√£o ‚Äî contagem de palavras, vetoriza√ß√£o com CountVectorizer e TF-IDF ‚Äî ser√£o geradas duas planilhas com:

Distribui√ß√£o absoluta: quantidade de avalia√ß√µes positivas e negativas, segmentadas por tipo de produto e marca.

Distribui√ß√£o percentual: representa√ß√£o em percentual dessas classifica√ß√µes nas mesmas segmenta√ß√µes.

Ao todo, ser√£o entregues 6 planilhas contendo uma vis√£o consolidada dos resultados obtidos em cada abordagem, permitindo compara√ß√µes detalhadas e facilitando a interpreta√ß√£o dos padr√µes de sentimento por produto e marca.

As tr√™s abordagens distintas para a classifica√ß√£o s√£o:

- Classificador por quantidade de palavras ‚Äî utiliza uma regra simples com base no n√∫mero de palavras positivas e negativas encontradas no texto.

- CountVectorizer ‚Äî t√©cnica de vetoriza√ß√£o que transforma o texto em uma matriz de frequ√™ncias de palavras, permitindo o uso de modelos de machine learning.

- TF-IDF (Term Frequency-Inverse Document Frequency) ‚Äî abordagem que pondera a import√¢ncia das palavras considerando a frequ√™ncia no corpus, resultando em vetores mais informativos para classifica√ß√£o.

## **3.0 Ferramentas utilizadas**

- **Python (Anaconda):** Pr√©-processamento, modelagem e avalia√ß√£o.
- **Pandas / seaborn / matplotlib/ Scikit-learn / nltk / re / wordcloud:** Bibliotecas para manipula√ß√£o e NLP.
- **Jupyter Notebook:** Ambiente de desenvolvimento.
- **ChatGpt:** IA generativa para criar o target das avalia√ß√µes. Essa classifica√ß√£o foi importante para o treinamento dos modelos supervisionados .
  
## **4.0 Desenvolvimento**

O desenvolvimento detalhado est√° dispon√≠vel no notebook Avalia√ß√£o de Produtos em anexo. 

As estapas implementadas s√£o:

- Cria√ß√£o de um prompt no chatgpt para gerar classifica√ß√µes das avalia√ß√µes. Sendo, 0: negativo e 1:positivo. Resultando na base de dados: avaliacoes_classificadas.csv.
- Importa√ß√£o, limpeza e pr√©-processamento dos dados textuais.
- Cria√ß√£o de tr√™s abordagens de classifica√ß√£o:
  -   **Classificador por contagem de palavras:** Abordagem simples e interpret√°vel, baseada na contagem de palavras positivas e negativas presentes nas avalia√ß√µes. Para isso, utilizei dois dicion√°rios previamente definidos: um com palavras de conota√ß√£o positiva e outro com palavras negativas.
  -   **Classifica√ß√£o com CountVectorizer:** Transforma os textos em vetores com base na frequ√™ncia de palavras. Modelo treinado com o algoritmo supervisionado Naive Bayes.
  -   **Classifica√ß√£o com TF-IDF:** Utiliza a pondera√ß√£o de termos para melhorar a relev√¢ncia dos vetores. Aplica√ß√£o do mesmo classificador com dados vetorizados. Modelo treinado com o algoritmo supervisionado Logistic Regressor.
- Avalia√ß√£o de desempenho dos modelos.
- Resultado dos modelos (planilhas com as classifica√ß√µes das avalia√ß√µes).
- Compara√ß√£o entre as abordagens.

## **5.0 Resultados**

O principal objetivo deste projeto foi implementar diferentes abordagens de classifica√ß√£o de sentimentos em avalia√ß√µes de produtos da Amazon, explorando as caracter√≠sticas, vantagens e desafios de cada t√©cnica.

üîπ Abordagem 1 ‚Äì Classificador por Contagem de Palavras
Nesta abordagem simples e interpret√°vel, as avalia√ß√µes foram classificadas com base na contagem de palavras positivas e negativas contidas nos textos, utilizando dois dicion√°rios customizados. Um dos principais desafios enfrentados foi a cria√ß√£o desses dicion√°rios base, que exigem uma curadoria cuidadosa para serem eficazes.

A elabora√ß√£o dos conjuntos de palavras positivas e negativas depende de uma avalia√ß√£o pr√©via das avalia√ß√µes reais, sendo ideal contar com o apoio da √°rea de opera√ß√£o ou especialistas do neg√≥cio para sugerirem termos representativos. Apesar de sua simplicidade e transpar√™ncia, essa abordagem demanda uma constante manuten√ß√£o e adapta√ß√£o dos dicion√°rios, o que pode limitar sua escalabilidade.

‚úÖ Pontos fortes: f√°cil de interpretar, sem necessidade de modelo supervisionado.

‚ö†Ô∏è Limita√ß√µes: depend√™ncia da qualidade dos dicion√°rios; baixa adaptabilidade a novos contextos.

üîπ Abordagem 2 ‚Äì Naive Bayes com CountVectorizer
Nesta abordagem, as avalia√ß√µes foram convertidas em vetores num√©ricos com base na frequ√™ncia absoluta das palavras (CountVectorizer) e classificadas por meio de um modelo supervisionado Naive Bayes.

A vetoriza√ß√£o simplificada captura a presen√ßa de palavras-chave, mas n√£o considera a import√¢ncia relativa dos termos no corpus. Ainda assim, o modelo demonstrou bom desempenho em bases balanceadas, sendo uma solu√ß√£o eficiente para conjuntos de dados moderadamente complexos.

‚úÖ Pontos fortes: r√°pida implementa√ß√£o, bom desempenho em bases simples.
‚ö†Ô∏è Limita√ß√µes: sens√≠vel a palavras comuns, pode superestimar termos irrelevantes e depende de um dataset previamente rotulado.

üîπ Abordagem 3 ‚Äì Regress√£o Log√≠stica com TF-IDF
Nesta abordagem, os textos foram vetorizados com TF-IDF (Term Frequency ‚Äì Inverse Document Frequency), que pondera a import√¢ncia de cada palavra com base em sua frequ√™ncia no documento e na base como um todo. O modelo de classifica√ß√£o utilizado foi uma Regress√£o Log√≠stica, amplamente aplicada em problemas de NLP pela sua capacidade de lidar com alta dimensionalidade e fornecer probabilidades associadas √†s previs√µes.

Comparada √†s demais abordagens, esta apresentou melhor equil√≠brio entre desempenho e generaliza√ß√£o, com menor tend√™ncia ao overfitting. Ainda assim, para uma aplica√ß√£o em produ√ß√£o, seria necess√°rio um cuidado maior na valida√ß√£o cruzada, ajuste de hiperpar√¢metros e testes com dados reais n√£o vistos.

‚úÖ Pontos fortes: vetoriza√ß√£o mais robusta, melhor generaliza√ß√£o, modelo bem compreendido.
‚ö†Ô∏è Limita√ß√µes: maior complexidade no ajuste e interpreta√ß√£o, sens√≠vel a ru√≠dos e tamb√©m requer um conjunto de dados rotulado para treinamento.

Considera√ß√µes Finais
A compara√ß√£o entre os m√©todos evidenciou que abordagens mais sofisticadas, como TF-IDF combinada com modelos supervisionados, tendem a oferecer maior precis√£o e capacidade de generaliza√ß√£o. No entanto, a contagem de palavras, ainda t√™m valor quando simplicidade, interpretabilidade e baixo custo computacional s√£o priorit√°rios.

Para aplica√ß√µes reais, recomenda-se:

- Refinamento dos dicion√°rios de sentimentos com apoio do time de neg√≥cio.
- Inclus√£o de valida√ß√£o cruzada e tuning de hiperpar√¢metros.
- Avalia√ß√£o de modelos mais avan√ßados, como Word2Vec, FastText ou BERT.






